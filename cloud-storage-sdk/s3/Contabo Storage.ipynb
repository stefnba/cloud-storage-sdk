{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contabo Storage\n",
    "\n",
    "Contabo Storage is a S3 compatible Object Storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "\n",
    "CONTABO_ACCESS_KEY_ID = os.getenv(\"CONTABO_ACCESS_KEY_ID\") or \"\"\n",
    "CONTABO_SECRET_ACCESS_KEY = os.getenv(\"CONTABO_SECRET_ACCESS_KEY\") or \"\"\n",
    "CONTABO_REGION = \"eu2\"\n",
    "CONTABO_ENDPOINT = f\"https://{CONTABO_REGION}.contabostorage.com\"\n",
    "\n",
    "storage = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=CONTABO_ENDPOINT,\n",
    "    region_name=CONTABO_REGION,\n",
    "    aws_access_key_id=CONTABO_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=CONTABO_SECRET_ACCESS_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket in storage.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Objects in Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in storage.Bucket(\"data-lake\").objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "duck = duckdb.connect()\n",
    "duck.execute(f\"SET s3_access_key_id='{CONTABO_ACCESS_KEY_ID}'\")\n",
    "duck.execute(f\"SET s3_secret_access_key='{CONTABO_SECRET_ACCESS_KEY}'\")\n",
    "duck.execute(f\"SET s3_region='{CONTABO_REGION}'\")\n",
    "duck.execute(\"SET s3_endpoint='eu2.contabostorage.com'\")\n",
    "duck.execute(\"SET s3_url_style='path'\")\n",
    "\n",
    "duck.read_parquet(\"s3://data-lake/part-0.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "storage_options = {\n",
    "    \"aws_endpoint_url\": f\"https://{CONTABO_REGION}.contabostorage.com\",\n",
    "    \"aws_access_key_id\": CONTABO_ACCESS_KEY_ID,\n",
    "    \"aws_secret_access_key\": CONTABO_SECRET_ACCESS_KEY,\n",
    "}\n",
    "\n",
    "df = pl.scan_parquet(\n",
    "    \"s3://data-lake/raw/part-0.parquet\",\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "df.head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyArrow dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "from pyarrow import fs\n",
    "\n",
    "filesystem = fs.S3FileSystem(\n",
    "    access_key=CONTABO_ACCESS_KEY_ID,\n",
    "    secret_key=CONTABO_SECRET_ACCESS_KEY,\n",
    "    endpoint_override=f\"{CONTABO_REGION}.contabostorage.com\",\n",
    ")\n",
    "\n",
    "dataset = ds.dataset(\"data-lake/raw/\", format=\"parquet\", filesystem=filesystem)\n",
    "dataset.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
